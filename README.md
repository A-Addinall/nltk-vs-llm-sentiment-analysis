# nltk-vs-llm-sentiment-analysis

This repository contains a project that compares two approaches for sentiment analysis: traditional Natural Language Processing (NLP) using NLTK (Natural Language Toolkit) and modern methods leveraging Large Language Models (LLMs). The project involves scraping data from a website, cleaning and preprocessing the text, and then applying sentiment analysis to identify positive, negative, or neutral sentiments in the text.

## Key Features:
- **Web Data Extraction:** Scraping and processing text data from a website.
- **NLTK Sentiment Analysis:** Using NLTK's built-in tools for sentiment classification.
- **LLM Sentiment Analysis:** Leveraging large language models for sentiment detection.
- **Comparison of Methods:** A detailed comparison between the results from NLTK-based sentiment analysis and LLM-based sentiment analysis.

## Objective:
The goal of this project is to explore the differences in sentiment accuracy and efficiency between these two techniques and provide insights into their performance on real-world data.

## Requirements:
To run the project, you need to install the following libraries:
- `nltk`
- `spacy`
- `transformers`
- `requests` (for web scraping)
- `beautifulsoup4` (for web scraping)
- `pandas` (for data manipulation)
- `matplotlib` (for visualisation)

You can install the dependencies using pip:

```bash
pip install -r requirements.txt
